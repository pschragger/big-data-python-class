{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reccomender\n",
    "\n",
    "Basing this tutorial from the work of Marcel Caraciolo at http://aimotion.blogspot.com/2012/08/introduction-to-recommendations-with.html\n",
    "\n",
    "Our goal is to calculate how similar pairs of movies are, so that we recommend movies similar to movies you liked.  Using the correlation we can:\n",
    "<ul>\n",
    "<li>For every pair of movies A and B, find all the people  who rated botha A and B.\n",
    "<li>Use these ratings to form a Movie A vector and a Movie B vector.\n",
    "<li>Calculate the correlation between those two vectors\n",
    "<li>When someone watches a movie, you can recommend the movies most correlated with it\n",
    "</ul>\n",
    "\n",
    "\n",
    "\n",
    "We are going to work of data set of movie ratings from: http://grouplens.org/datasets/movielens/\n",
    "For this task we will use the MovieLens Dataset of Movie Ratings with 10.000 ratings from 1000 users on 1700 movies (you can download it at this http://www.grouplens.org/node/73 ).\n",
    "\n",
    "\n",
    "So the first step is to get our movies file which has three columns:  (user, movie, rating). For this task we will use the MovieLens Dataset of Movie Ratings with 10.000 ratings\n",
    "\n",
    "You want to compute how similar pairs of movies are, so that if someone watches the movie The Matrix, you can recommend movies like BladeRunner. So how should you define the similarity between two movies ?\n",
    "\n",
    "One possibility is to compute their correlation. The basic idea behind it is for every pair of movies A and B, find all the people who rated both A and B. Use these ratings to form a Movie A vector and a Movie B vector.  Then, calculate the correlation between these two vectors.  Now when someone watches a movie, you can now recommend him the movies most correlated with it.\n",
    "\n",
    "So let's divide to conquer. Our first task is for each user, emit a row containing their 'postings' (item, rating). And for reducer, emit the user rating sum and count for use later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_by_user_rating(self, key, line):\n",
    "    \"\"\"\n",
    "    Emit the user_id and group by their ratings (item and rating)\n",
    "    17  70,3\n",
    "    35  21,1\n",
    "    49  19,2\n",
    "    49  21,1\n",
    "    49  70,4\n",
    "    87  19,1\n",
    "    87  21,2\n",
    "    98  19,2\n",
    "    \"\"\"\n",
    "    user_id, item_id, rating = line.split('|')\n",
    "    #yield (item_id, int(rating)), user_id\n",
    "    #yield item_id, (user_id, int(rating))\n",
    "    yield  user_id, (item_id, float(rating))\n",
    "    #yield (user_id, item_id), int(rating)\n",
    "\n",
    "def count_ratings_users_freq(self, user_id, values):\n",
    "    \"\"\"\n",
    "    For each user, emit a row containing their \"postings\"\n",
    "    (item,rating pairs)\n",
    "    Also emit user rating sum and count for use later steps.\n",
    "    17    1,3,(70,3)\n",
    "    35    1,1,(21,1)\n",
    "    49    3,7,(19,2 21,1 70,4)\n",
    "    87    2,3,(19,1 21,2)\n",
    "    98    1,2,(19,2)\n",
    "    \"\"\"\n",
    "    item_count = 0\n",
    "    item_sum = 0\n",
    "    final = []\n",
    "    for item_id, rating in values:\n",
    "        item_count += 1\n",
    "        item_sum += rating\n",
    "        final.append((item_id, rating))\n",
    "\n",
    "    yield user_id, (item_count, item_sum, final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Before using these rating pairs to calculate correlation,  let's see how we can compute it.  We know that they can be formed as vectors of ratings, so we can use linear algebra to perform norms and dot products, as alo to compute the length of each vector or the sum over all elements in each vector. By representing them as matrices, we can perform several operations on those movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<ipython-input-3-454335f55961>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-454335f55961>\"\u001b[1;36m, line \u001b[1;32m21\u001b[0m\n\u001b[1;33m    def calculate_similarity(self, pair_key, lines):\u001b[0m\n\u001b[1;37m                                                    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "  def pairwise_items(self, user_id, values):\n",
    "        '''\n",
    "        The output drops the user from the key entirely, instead it emits\n",
    "        the pair of items as the key:\n",
    "        19,21  2,1\n",
    "        19,70  2,4\n",
    "        21,70  1,4\n",
    "        19,21  1,2\n",
    "        This mapper is the main performance bottleneck.  One improvement\n",
    "        would be to create a java Combiner to aggregate the\n",
    "        outputs by key before writing to hdfs, another would be to use\n",
    "        a vector format and SequenceFiles instead of streaming text\n",
    "        for the matrix data.\n",
    "        '''\n",
    "        item_count, item_sum, ratings = values\n",
    "        #print item_count, item_sum, [r for r in combinations(ratings, 2)]\n",
    "        #bottleneck at combinations\n",
    "        for item1, item2 in combinations(ratings, 2):\n",
    "            yield (item1[0], item2[0]), \\\n",
    "                    (item1[1], item2[1])\n",
    "\n",
    "    def calculate_similarity(self, pair_key, lines):\n",
    "        '''\n",
    "        Sum components of each corating pair across all users who rated both\n",
    "        item x and item y, then calculate pairwise pearson similarity and\n",
    "        corating counts.  The similarities are normalized to the [0,1] scale\n",
    "        because we do a numerical sort.\n",
    "        19,21   0.4,2\n",
    "        21,19   0.4,2\n",
    "        19,70   0.6,1\n",
    "        70,19   0.6,1\n",
    "        21,70   0.1,1\n",
    "        70,21   0.1,1\n",
    "        '''\n",
    "        sum_xx, sum_xy, sum_yy, sum_x, sum_y, n = (0.0, 0.0, 0.0, 0.0, 0.0, 0)\n",
    "        item_pair, co_ratings = pair_key, lines\n",
    "        item_xname, item_yname = item_pair\n",
    "        for item_x, item_y in lines:\n",
    "            sum_xx += item_x * item_x\n",
    "            sum_yy += item_y * item_y\n",
    "            sum_xy += item_x * item_y\n",
    "            sum_y += item_y\n",
    "            sum_x += item_x\n",
    "            n += 1\n",
    "        similarity = normalized_correlation(n, sum_xy, sum_x, sum_y, \\\n",
    "                sum_xx, sum_yy)\n",
    "        yield (item_xname, item_yname), (similarity, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, each row in calculate similarity will compute the number of people who rated both movie and movie2 , the sum over all elements in each ratings vectors (sum_x, sum_y) and the squared sum of each vector (sum_xx, sum__yy). So  we can now can calculate the correlation between the movies. The correlation can be expressed as:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "So that's it! Now the last step of the job that will sort the top-correlated items for each item and print it to the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def calculate_ranking(self, item_keys, values):\n",
    "        '''\n",
    "        Emit items with similarity in key for ranking:\n",
    "        19,0.4    70,1\n",
    "        19,0.6    21,2\n",
    "        21,0.6    19,2\n",
    "        21,0.9    70,1\n",
    "        70,0.4    19,1\n",
    "        70,0.9    21,1\n",
    "        '''\n",
    "        similarity, n = values\n",
    "        item_x, item_y = item_keys\n",
    "        if int(n) > 0:\n",
    "            yield (item_x, similarity), (item_y, n)\n",
    "\n",
    "    def top_similar_items(self, key_sim, similar_ns):\n",
    "        '''\n",
    "        For each item emit K closest items in comma separated file:\n",
    "        De La Soul;A Tribe Called Quest;0.6;1\n",
    "        De La Soul;2Pac;0.4;2\n",
    "        '''\n",
    "        item_x, similarity = key_sim\n",
    "        for item_y, n in similar_ns:\n",
    "            print '%s;%s;%f;%d' % (item_x, item_y, similarity, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of it in one file  MovieSimilarities.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load code/MovieSimilarities.py\n",
    "\n",
    "'''\n",
    " Given a dataset of movies and their ratings by different\n",
    " users, how can we compute the similarity between pairs of\n",
    " movies?\n",
    " This module computes similarities between movies\n",
    " by representing each movie as a vector of ratings and\n",
    " computing similarity scores over these vectors. \n",
    " Copied from:\n",
    " https://github.com/marcelcaraciolo/recsys-mapreduce-mrjob/blob/master/moviesSimilarities.py\n",
    "'''\n",
    "__author__ = 'Marcel Caraciolo <caraciol@gmail.com>'\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from metrics import  correlation\n",
    "from metrics import cosine, regularized_correlation\n",
    "from math import sqrt\n",
    "\n",
    "try:\n",
    "    from itertools import combinations\n",
    "except ImportError:\n",
    "    from metrics import combinations\n",
    "\n",
    "\n",
    "PRIOR_COUNT = 10\n",
    "PRIOR_CORRELATION = 0\n",
    "\n",
    "\n",
    "class SemicolonValueProtocol(object):\n",
    "\n",
    "    # don't need to implement read() since we aren't using it\n",
    "\n",
    "    def write(self, key, values):\n",
    "        return ';'.join(str(v) for v in values)\n",
    "\n",
    "\n",
    "class MoviesSimilarities(MRJob):\n",
    "\n",
    "    OUTPUT_PROTOCOL = SemicolonValueProtocol\n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            self.mr(mapper=self.group_by_user_rating,\n",
    "                    reducer=self.count_ratings_users_freq),\n",
    "            self.mr(mapper=self.pairwise_items,\n",
    "                    reducer=self.calculate_similarity),\n",
    "            self.mr(mapper=self.calculate_ranking,\n",
    "                    reducer=self.top_similar_items)]\n",
    "\n",
    "    def group_by_user_rating(self, key, line):\n",
    "        \"\"\"\n",
    "        Emit the user_id and group by their ratings (item and rating)\n",
    "        17  70,3\n",
    "        35  21,1\n",
    "        49  19,2\n",
    "        49  21,1\n",
    "        49  70,4\n",
    "        87  19,1\n",
    "        87  21,2\n",
    "        98  19,2\n",
    "        \"\"\"\n",
    "        user_id, item_id, rating = line.split('|')\n",
    "        #yield (item_id, int(rating)), user_id\n",
    "        #yield item_id, (user_id, int(rating))\n",
    "        yield  user_id, (item_id, float(rating))\n",
    "        #yield (user_id, item_id), int(rating)\n",
    "\n",
    "    def count_ratings_users_freq(self, user_id, values):\n",
    "        \"\"\"\n",
    "        For each user, emit a row containing their \"postings\"\n",
    "        (item,rating pairs)\n",
    "        Also emit user rating sum and count for use later steps.\n",
    "        17    1,3,(70,3)\n",
    "        35    1,1,(21,1)\n",
    "        49    3,7,(19,2 21,1 70,4)\n",
    "        87    2,3,(19,1 21,2)\n",
    "        98    1,2,(19,2)\n",
    "        \"\"\"\n",
    "        item_count = 0\n",
    "        item_sum = 0\n",
    "        final = []\n",
    "        for item_id, rating in values:\n",
    "            item_count += 1\n",
    "            item_sum += rating\n",
    "            final.append((item_id, rating))\n",
    "\n",
    "        yield user_id, (item_count, item_sum, final)\n",
    "\n",
    "    def pairwise_items(self, user_id, values):\n",
    "        '''\n",
    "        The output drops the user from the key entirely, instead it emits\n",
    "        the pair of items as the key:\n",
    "        19,21  2,1\n",
    "        19,70  2,4\n",
    "        21,70  1,4\n",
    "        19,21  1,2\n",
    "        This mapper is the main performance bottleneck.  One improvement\n",
    "        would be to create a java Combiner to aggregate the\n",
    "        outputs by key before writing to hdfs, another would be to use\n",
    "        a vector format and SequenceFiles instead of streaming text\n",
    "        for the matrix data.\n",
    "        '''\n",
    "        item_count, item_sum, ratings = values\n",
    "        #print item_count, item_sum, [r for r in combinations(ratings, 2)]\n",
    "        #bottleneck at combinations\n",
    "        for item1, item2 in combinations(ratings, 2):\n",
    "            yield (item1[0], item2[0]), \\\n",
    "                    (item1[1], item2[1])\n",
    "\n",
    "    def calculate_similarity(self, pair_key, lines):\n",
    "        '''\n",
    "        Sum components of each corating pair across all users who rated both\n",
    "        item x and item y, then calculate pairwise pearson similarity and\n",
    "        corating counts.  The similarities are normalized to the [0,1] scale\n",
    "        because we do a numerical sort.\n",
    "        19,21   0.4,2\n",
    "        21,19   0.4,2\n",
    "        19,70   0.6,1\n",
    "        70,19   0.6,1\n",
    "        21,70   0.1,1\n",
    "        70,21   0.1,1\n",
    "        '''\n",
    "        sum_xx, sum_xy, sum_yy, sum_x, sum_y, n = (0.0, 0.0, 0.0, 0.0, 0.0, 0)\n",
    "        item_pair, co_ratings = pair_key, lines\n",
    "        item_xname, item_yname = item_pair\n",
    "        for item_x, item_y in lines:\n",
    "            sum_xx += item_x * item_x\n",
    "            sum_yy += item_y * item_y\n",
    "            sum_xy += item_x * item_y\n",
    "            sum_y += item_y\n",
    "            sum_x += item_x\n",
    "            n += 1\n",
    "\n",
    "        corr_sim = correlation(n, sum_xy, sum_x, \\\n",
    "                 sum_y, sum_xx, sum_yy)\n",
    "\n",
    "        reg_corr_sim = regularized_correlation(n, sum_xy, sum_x, \\\n",
    "                sum_y, sum_xx, sum_yy, PRIOR_COUNT, PRIOR_CORRELATION)\n",
    "\n",
    "        cos_sim = cosine(sum_xy, sqrt(sum_xx), sqrt(sum_yy))\n",
    "\n",
    "        jaccard_sim = 0.0\n",
    "\n",
    "        yield (item_xname, item_yname), (corr_sim, \\\n",
    "                cos_sim, reg_corr_sim, jaccard_sim, n)\n",
    "\n",
    "    def calculate_ranking(self, item_keys, values):\n",
    "        '''\n",
    "        Emit items with similarity in key for ranking:\n",
    "        19,0.4    70,1\n",
    "        19,0.6    21,2\n",
    "        21,0.6    19,2\n",
    "        21,0.9    70,1\n",
    "        70,0.4    19,1\n",
    "        70,0.9    21,1\n",
    "        '''\n",
    "        corr_sim, cos_sim, reg_corr_sim, jaccard_sim, n = values\n",
    "        item_x, item_y = item_keys\n",
    "        if int(n) > 0:\n",
    "            yield (item_x, corr_sim, cos_sim, reg_corr_sim, jaccard_sim), \\\n",
    "                     (item_y, n)\n",
    "\n",
    "    def top_similar_items(self, key_sim, similar_ns):\n",
    "        '''\n",
    "        For each item emit K closest items in comma separated file:\n",
    "        De La Soul;A Tribe Called Quest;0.6;1\n",
    "        De La Soul;2Pac;0.4;2\n",
    "        '''\n",
    "        item_x, corr_sim, cos_sim, reg_corr_sim, jaccard_sim = key_sim\n",
    "        for item_y, n in similar_ns:\n",
    "            yield None, (item_x, item_y, corr_sim, cos_sim, reg_corr_sim,\n",
    "                         jaccard_sim, n)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MoviesSimilarities.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "no configs found; falling back on auto-configuration\n",
      "INFO:mrjob.conf:no configs found; falling back on auto-configuration\n",
      "no configs found; falling back on auto-configuration\n",
      "INFO:mrjob.conf:no configs found; falling back on auto-configuration\n",
      "creating tmp directory c:\\users\\ps\\appdata\\local\\temp\\MovieSimilarities.PS.20151117.050611.748000\n",
      "INFO:mrjob.runner:creating tmp directory c:\\users\\ps\\appdata\\local\\temp\\MovieSimilarities.PS.20151117.050611.748000\n",
      "\n",
      "WARNING:mrjob.runner:\n",
      "PLEASE NOTE: Starting in mrjob v0.5.0, protocols will be strict by default. It's recommended you run your job with --strict-protocols or set up mrjob.conf as described at https://pythonhosted.org/mrjob/whats-new.html#ready-for-strict-protocols\n",
      "WARNING:mrjob.runner:PLEASE NOTE: Starting in mrjob v0.5.0, protocols will be strict by default. It's recommended you run your job with --strict-protocols or set up mrjob.conf as described at https://pythonhosted.org/mrjob/whats-new.html#ready-for-strict-protocols\n",
      "\n",
      "WARNING:mrjob.runner:\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "writing to c:\\users\\ps\\appdata\\local\\temp\\MovieSimilarities.PS.20151117.050611.748000\\step-0-mapper_part-00000\n",
      "INFO:mrjob.sim:writing to c:\\users\\ps\\appdata\\local\\temp\\MovieSimilarities.PS.20151117.050611.748000\\step-0-mapper_part-00000\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need more than 1 value to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\PS\\Documents\\GitHub\\big-data-python-class\\Lectures\\Lecture9- Recommenders\\code\\MovieSimilarities.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m     \u001b[0mMoviesSimilarities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\PS\\Anaconda\\lib\\site-packages\\mrjob\\job.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[1;31m# load options from the command line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[0mmr_job\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_READ_ARGS_FROM_SYS_ARGV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m         \u001b[0mmr_job\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\PS\\Anaconda\\lib\\site-packages\\mrjob\\job.pyc\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMRJob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_runner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\PS\\Anaconda\\lib\\site-packages\\mrjob\\launch.pyc\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;31m# Launcher only runs jobs, doesn't do any Hadoop Streaming stuff\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_job\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_runner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\PS\\Anaconda\\lib\\site-packages\\mrjob\\launch.pyc\u001b[0m in \u001b[0;36mrun_job\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_runner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mrunner\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\PS\\Anaconda\\lib\\site-packages\\mrjob\\runner.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    468\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Job already ran!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ran_job\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\PS\\Anaconda\\lib\\site-packages\\mrjob\\sim.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_counters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invoke_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mapper'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'reducer'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\PS\\Anaconda\\lib\\site-packages\\mrjob\\sim.pyc\u001b[0m in \u001b[0;36m_invoke_step\u001b[1;34m(self, step_num, step_type)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             self._run_step(step_num, step_type, input_path, output_path,\n\u001b[1;32m--> 260\u001b[1;33m                            working_dir, env)\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prev_outfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\PS\\Anaconda\\lib\\site-packages\\mrjob\\inline.pyc\u001b[0m in \u001b[0;36m_run_step\u001b[1;34m(self, step_num, step_type, input_path, output_path, working_dir, env, child_stdin)\u001b[0m\n\u001b[0;32m    158\u001b[0m                 \u001b[0mchild_instance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mrjob_cls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchild_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m                 \u001b[0mchild_instance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msandbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstdin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchild_stdin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchild_stdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m                 \u001b[0mchild_instance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhas_combiner\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\PS\\Anaconda\\lib\\site-packages\\mrjob\\job.pyc\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_mapper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_mapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_combiner\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\PS\\Anaconda\\lib\\site-packages\\mrjob\\job.pyc\u001b[0m in \u001b[0;36mrun_mapper\u001b[1;34m(self, step_num)\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;31m# run the mapper on each line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mout_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_value\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m                 \u001b[0mwrite_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\PS\\Documents\\GitHub\\big-data-python-class\\Lectures\\Lecture9- Recommenders\\code\\MovieSimilarities.py\u001b[0m in \u001b[0;36mgroup_by_user_rating\u001b[1;34m(self, key, line)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;36m98\u001b[0m  \u001b[1;36m19\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \"\"\"\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0muser_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'|'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;31m#yield (item_id, int(rating)), user_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;31m#yield item_id, (user_id, int(rating))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: need more than 1 value to unpack"
     ]
    }
   ],
   "source": [
    "%run code/MovieSimilarities.py data/ml-100k/ml-100k/u.data > data/output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
